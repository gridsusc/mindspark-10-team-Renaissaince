{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fffe010b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6f679755",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>id</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>130.749</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.357</td>\n",
       "      <td>244573</td>\n",
       "      <td>-7.843</td>\n",
       "      <td>0.531</td>\n",
       "      <td>3kdMzXOcrDIdSWLdONHNK5</td>\n",
       "      <td>Energetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>129.022</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.713000</td>\n",
       "      <td>0.594</td>\n",
       "      <td>205760</td>\n",
       "      <td>-3.210</td>\n",
       "      <td>0.899</td>\n",
       "      <td>3rFEKOClXOdNFO6fQGuQ9j</td>\n",
       "      <td>Energetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>130.037</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.512</td>\n",
       "      <td>198081</td>\n",
       "      <td>-5.912</td>\n",
       "      <td>0.531</td>\n",
       "      <td>4G3DWijMhNkWZwLcxnDI0H</td>\n",
       "      <td>Energetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>126.037</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.542</td>\n",
       "      <td>194626</td>\n",
       "      <td>-3.910</td>\n",
       "      <td>0.785</td>\n",
       "      <td>4YZVtRbdGOhHdGNi4JpCL5</td>\n",
       "      <td>Energetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>161.939</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.252</td>\n",
       "      <td>210560</td>\n",
       "      <td>-4.678</td>\n",
       "      <td>0.498</td>\n",
       "      <td>7GvkOFkNsM6Exnkyqeajqm</td>\n",
       "      <td>Energetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>94</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>122.017</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.653</td>\n",
       "      <td>197347</td>\n",
       "      <td>-3.725</td>\n",
       "      <td>0.697</td>\n",
       "      <td>03mMSLEJCPoGJwQhHpN5y0</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>95</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>125.988</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>193997</td>\n",
       "      <td>-6.412</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0tnB2ZH4DbjLjCBmdr5VXz</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>96</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>75.011</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786</td>\n",
       "      <td>156505</td>\n",
       "      <td>-3.777</td>\n",
       "      <td>0.685</td>\n",
       "      <td>3orJ0XpgXRG1LTA521BpDz</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>97</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>139.475</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591</td>\n",
       "      <td>129867</td>\n",
       "      <td>-8.583</td>\n",
       "      <td>0.759</td>\n",
       "      <td>4Nlif8FMSkyegKgukC31Yi</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>98</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>144.996</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.611</td>\n",
       "      <td>164200</td>\n",
       "      <td>-6.571</td>\n",
       "      <td>0.771</td>\n",
       "      <td>6J7U49QGecWb3WqIqfSYc0</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  energy  liveness    tempo  speechiness  acousticness  \\\n",
       "0             0   0.549    0.2200  130.749       0.0698      0.000798   \n",
       "1             1   0.975    0.1600  129.022       0.0618      0.000051   \n",
       "2             2   0.724    0.2370  130.037       0.0313      0.000827   \n",
       "3             3   0.828    0.0600  126.037       0.0536      0.001750   \n",
       "4             4   0.886    0.2560  161.939       0.0714      0.000029   \n",
       "..          ...     ...       ...      ...          ...           ...   \n",
       "478          94   0.869    0.0460  122.017       0.0382      0.128000   \n",
       "479          95   0.842    0.0601  125.988       0.1030      0.000417   \n",
       "480          96   0.588    0.1670   75.011       0.1650      0.050300   \n",
       "481          97   0.688    0.1690  139.475       0.0414      0.248000   \n",
       "482          98   0.880    0.0598  144.996       0.0378      0.000817   \n",
       "\n",
       "     instrumentalness  danceability  duration_ms  loudness  valence  \\\n",
       "0            0.004850         0.357       244573    -7.843    0.531   \n",
       "1            0.713000         0.594       205760    -3.210    0.899   \n",
       "2            0.000144         0.512       198081    -5.912    0.531   \n",
       "3            0.013600         0.542       194626    -3.910    0.785   \n",
       "4            0.000005         0.252       210560    -4.678    0.498   \n",
       "..                ...           ...          ...       ...      ...   \n",
       "478          0.000022         0.653       197347    -3.725    0.697   \n",
       "479          0.835000         0.825       193997    -6.412    0.440   \n",
       "480          0.000000         0.786       156505    -3.777    0.685   \n",
       "481          0.000000         0.591       129867    -8.583    0.759   \n",
       "482          0.000010         0.611       164200    -6.571    0.771   \n",
       "\n",
       "                         id       mood  \n",
       "0    3kdMzXOcrDIdSWLdONHNK5  Energetic  \n",
       "1    3rFEKOClXOdNFO6fQGuQ9j  Energetic  \n",
       "2    4G3DWijMhNkWZwLcxnDI0H  Energetic  \n",
       "3    4YZVtRbdGOhHdGNi4JpCL5  Energetic  \n",
       "4    7GvkOFkNsM6Exnkyqeajqm  Energetic  \n",
       "..                      ...        ...  \n",
       "478  03mMSLEJCPoGJwQhHpN5y0      Happy  \n",
       "479  0tnB2ZH4DbjLjCBmdr5VXz      Happy  \n",
       "480  3orJ0XpgXRG1LTA521BpDz      Happy  \n",
       "481  4Nlif8FMSkyegKgukC31Yi      Happy  \n",
       "482  6J7U49QGecWb3WqIqfSYc0      Happy  \n",
       "\n",
       "[483 rows x 13 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tracks.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1883d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data[[\"energy\", \"liveness\", \"tempo\", \"speechiness\",\"acousticness\",\"instrumentalness\",\"danceability\", \"loudness\",\"valence\"]]\n",
    "# X = data[[\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\n",
    "# \"instrumentalness\", \"liveness\", \"valance\", \"tempo\"]]\n",
    "y = data[\"mood\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5c5f3d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.04670</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>80.010</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>-20.727</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.86200</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>123.994</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.791</td>\n",
       "      <td>-3.240</td>\n",
       "      <td>0.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.00128</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>70.752</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-34.908</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.18000</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>62.392</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-22.992</td>\n",
       "      <td>0.0307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.86600</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>128.038</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-3.804</td>\n",
       "      <td>0.6190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.04150</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>67.435</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-26.378</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.82100</td>\n",
       "      <td>0.0823</td>\n",
       "      <td>120.462</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-3.974</td>\n",
       "      <td>0.3310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.83400</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>135.974</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523</td>\n",
       "      <td>-5.133</td>\n",
       "      <td>0.5590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.88600</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>97.012</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673</td>\n",
       "      <td>-4.440</td>\n",
       "      <td>0.7950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.14800</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>143.578</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-19.361</td>\n",
       "      <td>0.0574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      energy  liveness    tempo  speechiness  acousticness  instrumentalness  \\\n",
       "157  0.04670    0.1150   80.010       0.0507      0.930000          0.785000   \n",
       "450  0.86200    0.0814  123.994       0.1100      0.037000          0.000022   \n",
       "118  0.00128    0.1100   70.752       0.0867      0.995000          0.978000   \n",
       "114  0.18000    0.1160   62.392       0.0433      0.628000          0.822000   \n",
       "440  0.86600    0.2570  128.038       0.0619      0.007010          0.000000   \n",
       "..       ...       ...      ...          ...           ...               ...   \n",
       "106  0.04150    0.1120   67.435       0.0392      0.952000          0.975000   \n",
       "270  0.82100    0.0823  120.462       0.1040      0.078500          0.000000   \n",
       "348  0.83400    0.4000  135.974       0.0366      0.000075          0.000000   \n",
       "435  0.88600    0.0826   97.012       0.0431      0.185000          0.000000   \n",
       "102  0.14800    0.0961  143.578       0.0339      0.603000          0.848000   \n",
       "\n",
       "     danceability  loudness  valence  \n",
       "157         0.748   -20.727   0.3010  \n",
       "450         0.791    -3.240   0.5920  \n",
       "118         0.469   -34.908   0.0000  \n",
       "114         0.202   -22.992   0.0307  \n",
       "440         0.578    -3.804   0.6190  \n",
       "..            ...       ...      ...  \n",
       "106         0.182   -26.378   0.0376  \n",
       "270         0.376    -3.974   0.3310  \n",
       "348         0.523    -5.133   0.5590  \n",
       "435         0.673    -4.440   0.7950  \n",
       "102         0.413   -19.361   0.0574  \n",
       "\n",
       "[323 rows x 9 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0990b99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157      Relaxing\n",
       "450         Happy\n",
       "118      Relaxing\n",
       "114      Relaxing\n",
       "440         Happy\n",
       "          ...    \n",
       "106      Relaxing\n",
       "270          Dark\n",
       "348    Aggressive\n",
       "435         Happy\n",
       "102      Relaxing\n",
       "Name: mood, Length: 323, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ebfb48e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\truon\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\truon\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\truon\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "24652e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9ee8dff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\truon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:39:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 62.50%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [value for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8891073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4973861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6375\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-7e4aca075bfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1-score:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \"\"\"\n\u001b[1;32m-> 1068\u001b[1;33m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[0;32m   1069\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \"\"\"\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1193\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1462\u001b[0m                                     pos_label)\n\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[0;32m   1292\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m                              % (y_type, average_options))\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1-score:\",metrics.f1_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e5471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
