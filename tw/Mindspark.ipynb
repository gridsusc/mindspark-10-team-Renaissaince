{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mindspark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "43n2citGlWl_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential ,model_from_json\n",
        "from tensorflow.keras.layers import Embedding,Dense,Dropout ,GlobalMaxPool1D"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing Data"
      ],
      "metadata": {
        "id": "r1di9eNWuHkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import TransformerMixin ,BaseEstimator\n",
        "class Extractor(BaseEstimator,TransformerMixin):\n",
        "    def transform(self,X,y=None):\n",
        "        return pd.read_csv('combined.csv', index_col=0)\n",
        "\n",
        "class Cleaner(BaseEstimator,TransformerMixin):\n",
        "    def transform(self,X,y=None):\n",
        "        columns=X.columns.tolist()\n",
        "        X.columns=[column.strip() for column in columns]\n",
        "        X=X.drop('tweet id',axis=1)\n",
        "        X=X.dropna()\n",
        "        X['tweet']=X['tweet'].str.replace('@', '')\n",
        "        X['tweet']=X['tweet'].str.replace('#', '')\n",
        "        X['tweet']=X['tweet'].str.replace('http\\S+', '',regex=True)\n",
        "        X['tweet']=X['tweet'].str.strip()\n",
        "        X['tweet']=X['tweet'].str.lower()        \n",
        "        return X\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "gIxpN7qLm11P"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampler(BaseEstimator,TransformerMixin):\n",
        "    def __init__(self, unrelated_size=None ,unrelated_ignore=True):\n",
        "        self.unrelated_size = unrelated_size\n",
        "        self.unrelated_ignore = unrelated_ignore\n",
        "        \n",
        "    def transform(self,X,y=None):\n",
        "        Xnew = X.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "        if self.unrelated_ignore:\n",
        "          Xnew['label']=Xnew.apply(lambda row: row['category'] if 'on-topic' in row['label'] else 'unrelated',axis=1 ) \n",
        "        else:\n",
        "          Xnew['label']=Xnew.apply(lambda row: row['category'] if 'on-topic' in row['label'] else 'unrelated_'+row['category'],axis=1 )  \n",
        "        \n",
        "        related,unrelated =self.equal_split(Xnew)\n",
        "        Xmerged = pd.DataFrame()\n",
        "        Xmerged = Xmerged.append(related)\n",
        "        Xmerged = Xmerged.append(unrelated)\n",
        "        X=Xmerged.drop('category',axis=1)       \n",
        "        return X\n",
        "            \n",
        "    \n",
        "    def equal_split(self,X):\n",
        "        related=X[X['label'].str.contains('unrelated')==False]\n",
        "        unrelated=X[X['label'].str.contains('unrelated')]\n",
        "\n",
        "        cat = pd.DataFrame(X['label'].value_counts())\n",
        "        cat = cat.drop('unrelated', axis=0)\n",
        "        avg = int(cat['label'].mean())\n",
        "\n",
        "        if self.unrelated_size is None:\n",
        "          self.unrelated_size = avg\n",
        "        if self.unrelated_size < unrelated.shape[0]:\n",
        "          unrelated = unrelated[:self.unrelated_size]\n",
        "\n",
        "        return related,unrelated  \n"
      ],
      "metadata": {
        "id": "Y8xEODMwnQXF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextTokenizer(BaseEstimator,TransformerMixin):\n",
        "    \n",
        "    def __init__(self,pad_sequences,num_words=10000,max_length=100,max_pad_length=100 ):\n",
        "        self._num_words=num_words\n",
        "        self.max_length=max_length\n",
        "        self._tokenizer=None\n",
        "        self._pad_sequences=pad_sequences\n",
        "        self._max_pad_length=max_pad_length\n",
        "        self.vocab_size=None\n",
        "        self.tokenizer=None\n",
        "        \n",
        "    def transform(self,X,y=None):\n",
        "        self.tokenizer,self.vocab_size=self._get_tokenizer(X['tweet'])\n",
        "        X['tweet_encoded']=self.tokenizer.texts_to_sequences(X['tweet'])\n",
        "        X['tweet_encoded']= X['tweet_encoded'].apply(lambda x: self._pad_sequences([x],maxlen=self._max_pad_length ,padding='post')[0])\n",
        "        return X\n",
        "        \n",
        "    def _get_tokenizer(self,X):\n",
        "        tokenizer=tf.keras.preprocessing.text.Tokenizer(num_words=self._num_words)\n",
        "        tokenizer.fit_on_texts(X)\n",
        "        vocab_size=len(tokenizer.word_index)+1\n",
        "        return tokenizer,vocab_size"
      ],
      "metadata": {
        "id": "q-4z4i7srZZy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelOneHotEncoder(BaseEstimator,TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.label_encoder=None\n",
        "        self.one_hot=None\n",
        "        \n",
        "    def transform(self,X,y=None):\n",
        "        self.label_encoder=LabelEncoder().fit(X['label'])\n",
        "        self.one_hot=to_categorical\n",
        "        num_classes=len(set(X['label']))\n",
        "        X['label_encoded']= self.label_encoder.transform(X['label'].values)\n",
        "        X['label_one_hot']= X['label_encoded'].apply(lambda x: self.one_hot([x],num_classes=num_classes)[0])   \n",
        "        \n",
        "        return X\n",
        "      "
      ],
      "metadata": {
        "id": "04oIPJa-rr3s"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PassThrough(BaseEstimator,TransformerMixin):\n",
        "    def transform(self,X,y=None):\n",
        "        return X\n",
        "    def fit(self,X,y=None):\n",
        "        return X"
      ],
      "metadata": {
        "id": "yXBhG-PHr34H"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded = tf.keras.preprocessing.sequence.pad_sequences\n",
        "\n",
        "\n",
        "pipeline =Pipeline(steps=[\n",
        "    ('extractor',Extractor()),\n",
        "    ('cleaner',Cleaner()),\n",
        "    ('distribution-validator',Sampler(unrelated_size=None ,unrelated_ignore=True)),\n",
        "    ('tokenizer',TextTokenizer(padded)),\n",
        "    ('one-hot-encoder',LabelOneHotEncoder()),\n",
        "    ('pass-through',PassThrough()),\n",
        "    \n",
        "])\n",
        "processed_output = pipeline.transform(None)\n",
        "processed_output.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NavxetrNr-WF",
        "outputId": "5e93431d-7adc-468b-b565-10257539d456"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                tweet      label  \\\n",
              "0   mt newstalk770: all but 3 in hillhurst, all br...     floods   \n",
              "6   bostonmarathon joeymcintyre this is by no mean...    bombing   \n",
              "7   dominicans r like hurricane?! we swim in river...  hurricane   \n",
              "10  “michaelskolnik: oklahoma senator tom coburn s...    tornado   \n",
              "11  okang readying the vehicles, and troops to sen...    tornado   \n",
              "\n",
              "                                        tweet_encoded  label_encoded  \\\n",
              "0   [520, 4385, 27, 70, 130, 3, 9145, 27, 5482, 20...              3   \n",
              "6   [149, 7761, 16, 10, 29, 74, 1376, 6, 158, 171,...              0   \n",
              "7   [266, 73, 12, 41, 3229, 3, 1137, 8, 806, 83, 2...              4   \n",
              "10  [24, 2111, 2026, 3511, 145, 3703, 1894, 565, 3...              5   \n",
              "11  [1, 2540, 7, 1128, 4, 323, 4, 110, 3, 6, 898, ...              5   \n",
              "\n",
              "                          label_one_hot  \n",
              "0   [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
              "6   [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
              "7   [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
              "10  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "11  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8253e70-08e3-4837-b882-7409bafd1bc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet_encoded</th>\n",
              "      <th>label_encoded</th>\n",
              "      <th>label_one_hot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mt newstalk770: all but 3 in hillhurst, all br...</td>\n",
              "      <td>floods</td>\n",
              "      <td>[520, 4385, 27, 70, 130, 3, 9145, 27, 5482, 20...</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bostonmarathon joeymcintyre this is by no mean...</td>\n",
              "      <td>bombing</td>\n",
              "      <td>[149, 7761, 16, 10, 29, 74, 1376, 6, 158, 171,...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>dominicans r like hurricane?! we swim in river...</td>\n",
              "      <td>hurricane</td>\n",
              "      <td>[266, 73, 12, 41, 3229, 3, 1137, 8, 806, 83, 2...</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>“michaelskolnik: oklahoma senator tom coburn s...</td>\n",
              "      <td>tornado</td>\n",
              "      <td>[24, 2111, 2026, 3511, 145, 3703, 1894, 565, 3...</td>\n",
              "      <td>5</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>okang readying the vehicles, and troops to sen...</td>\n",
              "      <td>tornado</td>\n",
              "      <td>[1, 2540, 7, 1128, 4, 323, 4, 110, 3, 6, 898, ...</td>\n",
              "      <td>5</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8253e70-08e3-4837-b882-7409bafd1bc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8253e70-08e3-4837-b882-7409bafd1bc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8253e70-08e3-4837-b882-7409bafd1bc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "gswgwH3ZuOCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test =train_test_split(processed_output['tweet_encoded'],processed_output['label_one_hot'],test_size=0.3,stratify=processed_output['label_encoded'])\n",
        "X_train, y_train = np.array(X_train.values.tolist()), np.array(y_train.values.tolist())\n",
        "X_test, y_test = np.array(X_test.values.tolist()), np.array(y_test.values.tolist())"
      ],
      "metadata": {
        "id": "SFAWMmPfsYn4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = pipeline.named_steps['tokenizer']\n",
        "max_length = tokenizer.max_length\n",
        "vocab_size = tokenizer.vocab_size\n",
        "embedding_dim = 50\n",
        "num_classes= y_train[0].shape[0]"
      ],
      "metadata": {
        "id": "XKF-58RduiDz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential([\n",
        "     Embedding(input_dim=vocab_size,output_dim=embedding_dim,input_length=max_length),\n",
        "     GlobalMaxPool1D(),\n",
        "     Dropout(0.2),\n",
        "     Dense(10,activation='relu'),\n",
        "     Dropout(0.2),\n",
        "     Dense(num_classes,activation='softmax')      \n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'] )\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73bUfryOu_Bp",
        "outputId": "cab151b9-b9ce-4efa-c18f-8ecbacecec06"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 50)           2297750   \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 50)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                510       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 77        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,298,337\n",
            "Trainable params: 2,298,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=4,batch_size=10,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAcI3GDCvgyu",
        "outputId": "67d17433-92b2-4820-82b3-a1314f721ffe"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "2420/2420 [==============================] - 69s 28ms/step - loss: 0.8164 - accuracy: 0.7212 - val_loss: 0.3146 - val_accuracy: 0.9159\n",
            "Epoch 2/4\n",
            "2420/2420 [==============================] - 69s 28ms/step - loss: 0.3695 - accuracy: 0.8909 - val_loss: 0.2691 - val_accuracy: 0.9220\n",
            "Epoch 3/4\n",
            "2420/2420 [==============================] - 68s 28ms/step - loss: 0.3011 - accuracy: 0.9097 - val_loss: 0.2566 - val_accuracy: 0.9255\n",
            "Epoch 4/4\n",
            "2420/2420 [==============================] - 67s 28ms/step - loss: 0.2549 - accuracy: 0.9230 - val_loss: 0.2605 - val_accuracy: 0.9245\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5c54b66790>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('tweets_model','w+') as f:\n",
        "  f.write(model.to_json())\n",
        "  model.save_weights('tweets_model.h5')"
      ],
      "metadata": {
        "id": "RSqxXJedv1Ov"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Model and Predictions"
      ],
      "metadata": {
        "id": "SGe2qnx0yHPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('tweets_model', 'r')\n",
        "model = model_from_json(f.read())\n",
        "f.close()\n",
        "model.load_weights('tweets_model.h5')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4tnItd-xaCV",
        "outputId": "2e16c43e-5ee4-40f8-dbf9-6e4e92ebe936"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 92.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Twitter data"
      ],
      "metadata": {
        "id": "bCaUz6Qxzn6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "\n",
        "api_key = \"9Dco5KZZ8lxl7NmFELl8pw10L\"\n",
        "api_key_secret = \"Nk3rpobh2QnzSBtGI0NkQcIZNgpzqgEhKtWvyLNPJOsePwwaun\"\n",
        "\n",
        "access_token = \"1188450720032231425-TZsQDD6u4Ajwpba2NaELZJTcQqnBtA\"\n",
        "access_token_secret = \"vpqrTMtcva9dq1bvgxtDZUfoT3ePa5sFKtk9WCGrz920p\"\n",
        "\n",
        "# authenticate\n",
        "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "NRpEooCPznfy"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = [\"flood\", \"earthquake\", \"hurricane\", \"tornado\", \"explosion\", \"bombing\", \"wildfire\" ]\n",
        "\n",
        "tweets_copy = []\n",
        "for query in search_query:\n",
        "\n",
        "  tweets = tweepy.Cursor(api.search,\n",
        "                q=query,\n",
        "                lang=\"en\",\n",
        "                since=\"2020-09-16\").items(50)\n",
        "\n",
        "\n",
        "  for tweet in tweets:\n",
        "      tweets_copy.append(tweet)\n",
        "    \n",
        "print(\"Total Tweets fetched:\", len(tweets_copy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jekJbuDvz1LS",
        "outputId": "8d9f9cb1-c2a2-4c81-a481-ae9ec8e08550"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tweets fetched: 350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tweets Prediction"
      ],
      "metadata": {
        "id": "_ljRYCi97_WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=pipeline.named_steps['tokenizer'].vocab_size\n",
        "max_length=pipeline.named_steps['tokenizer'].max_length\n",
        "label_encoder=pipeline.named_steps['one-hot-encoder'].label_encoder\n",
        "tokenizer=pipeline.named_steps['tokenizer'].tokenizer\n",
        "max_length=pipeline.named_steps['tokenizer'].max_length"
      ],
      "metadata": {
        "id": "eXos1vGW7Siu"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  x=[tweets_copy[i]._json['text']]\n",
        "\n",
        "  x_seq=tokenizer.texts_to_sequences(x)[0]\n",
        "  x_pad=tf.keras.preprocessing.sequence.pad_sequences([x_seq],maxlen=max_length ,padding='post')[0]\n",
        "  x_pad=np.array(x_pad)\n",
        "  x_pad=x_pad.reshape(1,100)\n",
        "  x_pad.shape\n",
        "  predict=model.predict(x_pad)[0].tolist()\n",
        "  score=max(model.predict(x_pad)[0])\n",
        "  print(predict.index(score))\n",
        "  print(label_encoder.inverse_transform([predict.index(score)]))\n",
        "  print('score', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QolpIfWK0B30",
        "outputId": "e13eb031-1571-4f38-c8ef-ee1fff1e3617"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "['floods']\n",
            "score 0.9991104\n",
            "3\n",
            "['floods']\n",
            "score 0.9995461\n",
            "3\n",
            "['floods']\n",
            "score 0.99898225\n",
            "3\n",
            "['floods']\n",
            "score 0.9992698\n",
            "6\n",
            "['unrelated']\n",
            "score 0.8477903\n",
            "3\n",
            "['floods']\n",
            "score 0.9993691\n",
            "3\n",
            "['floods']\n",
            "score 0.999713\n",
            "3\n",
            "['floods']\n",
            "score 0.9995461\n",
            "6\n",
            "['unrelated']\n",
            "score 0.94782984\n",
            "3\n",
            "['floods']\n",
            "score 0.9988261\n",
            "3\n",
            "['floods']\n",
            "score 0.99898225\n",
            "3\n",
            "['floods']\n",
            "score 0.9993316\n",
            "3\n",
            "['floods']\n",
            "score 0.9995461\n",
            "3\n",
            "['floods']\n",
            "score 0.99898225\n",
            "6\n",
            "['unrelated']\n",
            "score 0.92994875\n",
            "3\n",
            "['floods']\n",
            "score 0.99901927\n",
            "3\n",
            "['floods']\n",
            "score 0.99898225\n",
            "3\n",
            "['floods']\n",
            "score 0.99957865\n",
            "3\n",
            "['floods']\n",
            "score 0.99908805\n",
            "3\n",
            "['floods']\n",
            "score 0.9995461\n"
          ]
        }
      ]
    }
  ]
}